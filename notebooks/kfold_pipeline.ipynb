{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import src.data_loader as data_loader\n",
    "import src.kfold.kfold_training_testing as kfold\n",
    "\n",
    "from dataclasses import dataclass, asdict\n",
    "from src.types import *\n",
    "from src.models.main_model import OB_05Model\n",
    "from src.kfold.kfold_training_config import KFoldTrainingConfig\n",
    "from src.visualization.model_evaluation import TrainingVisualizations, TestingVisualizations\n",
    "\n",
    "output_dir = \"../output/kfold_model\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Getting the datasets per fold\n",
    "raw_dataset_per_fold = data_loader.KFold.split_into_n_sub_datasets(2)\n",
    "\n",
    "# logger for output (we can output training data to stdout or a file for example)\n",
    "logger = logging.getLogger(\"logger\")\n",
    "logger.setLevel(logging.INFO)\n",
    "console_handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "model = OB_05Model()\n",
    "\n",
    "initial_learning_rate = 0.0001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=initial_learning_rate, weight_decay=5e-2)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5)\n",
    "\n",
    "training_config = KFoldTrainingConfig(\n",
    "    model_name=\"kfold_model\",\n",
    "    output_dir=output_dir,\n",
    "    output_logger=logger,\n",
    "    \n",
    "    folds=raw_dataset_per_fold,\n",
    "    classes=data_loader.get_trainset().classes,\n",
    "    \n",
    "    epochs_per_fold=2,\n",
    "    initial_learning_rate=initial_learning_rate,\n",
    "    patience=5,\n",
    "    \n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler\n",
    ")"
   ],
   "id": "ac4a86b303ee7506",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# K-fold",
   "id": "78def7bc68d0352f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results_per_fold = kfold.kfold_cross_validation(training_config)",
   "id": "fbba66574c3d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for (training_logger, evaluation_results) in results_per_fold:\n",
    "    df = evaluation_results.get_metrics_table_as_df()\n",
    "    print(df)"
   ],
   "id": "3dc38a2a15620416",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = []\n",
    "for (training_logger, evaluation_results) in results_per_fold:\n",
    "    macro_precision, macro_recall, macro_f1_score, macro_accuracy = utils.cm_macro.calculate_overall_metrics(\n",
    "        evaluation_results.confusion_matrix)\n",
    "    micro_precision, micro_recall, micro_f1_score, micro_accuracy = utils.cm_micro.calculate_overall_metrics(\n",
    "        evaluation_results.confusion_matrix)\n",
    "    accuracy = (macro_accuracy + micro_accuracy) / 2  # should be the same for both\n",
    "    data.append(\n",
    "        [macro_precision, macro_recall, macro_f1_score, micro_precision, micro_recall, micro_f1_score, accuracy]\n",
    "    )\n",
    "\n",
    "\n",
    "tuples = [(\"macro\", \"precision\"), (\"macro\", \"recall\"), (\"macro\", \"f1_score\"), (\"micro\", \"precision\"),\n",
    "          (\"micro\", \"recall\"), (\"micro\", \"f1_score\"), (\"\", \"accuracy\")]\n",
    "\n",
    "temp_df = pd.DataFrame(data, \n",
    "                       index=pd.Index(range(1, len(results_per_fold) + 1)), \n",
    "                       columns=pd.MultiIndex.from_tuples(tuples, names=[\"\", \"fold\"]))\n",
    "\n",
    "averages = list(tuples \n",
    "                | pipe.select(lambda key: np.array(df[key])) \n",
    "                | pipe.select(lambda arr: np.mean(arr)))\n",
    "data.append(averages)\n",
    "\n",
    "indices = list(range(1, len(results_per_fold) + 1)) + [\"average\"]\n",
    "df = pd.DataFrame(data, \n",
    "                  index=pd.Index(indices), \n",
    "                  columns=pd.MultiIndex.from_tuples(tuples, names=[\"\", \"fold\"]))\n",
    "\n",
    "df.style"
   ],
   "id": "822927e2b93b6130",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "list(next(df.iterrows()))",
   "id": "9cd9ef635f93f67c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# list(df[(\"macro\", \"precision\")])\n",
    "\n",
    "import pipe\n",
    "\n",
    "averages = list(tuples\n",
    "                | pipe.select(lambda key: np.array(df[key]))\n",
    "                | pipe.select(lambda arr: np.mean(arr)))\n",
    "\n",
    "as_row = dict(zip(tuples, averages))\n",
    "as_row\n",
    "\n",
    "df.loc[len(df)] = as_row"
   ],
   "id": "f63442ae6eeadeba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df",
   "id": "954166f8cb74c6e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import src.types as tps\n",
    "\n",
    "evaluation_results_list = list(results_per_fold | pipe.select(lambda pair: pair[1]))\n",
    "df = tps.EvaluationResults.format_evaluation_results_as_df(evaluation_results_list)\n",
    "df.style"
   ],
   "id": "b3a60c6aa18fcb32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import src.types as tps\n",
    "\n",
    "# Deserialize and load from a file\n",
    "with open('../output/kfold_model/results.pkl', 'rb') as f:\n",
    "    results_per_fold = pickle.load(f)\n",
    "    \n",
    "evaluation_results_list = list(results_per_fold | pipe.select(lambda pair: pair[1]))\n",
    "df = tps.EvaluationResults.format_evaluation_results_as_df(evaluation_results_list)\n",
    "df.style"
   ],
   "id": "4ed658b676845e43",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
