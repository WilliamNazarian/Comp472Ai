{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "!git init\n",
    "\n",
    "# Uses (restricted) GitHub token to access private repo\n",
    "# Valid for 30 days starting 6/15/2024\n",
    "!git remote add origin https://bryjen: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@github.com/WilliamNazarian/Comp472Ai.git\n",
    "!git fetch origin\n",
    "!git reset --hard origin/main"
   ],
   "metadata": {
    "id": "rczGAM1py96-"
   },
   "id": "rczGAM1py96-",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%%capture\n",
    "!pip install -r requirements.txt\n",
    "!pip install pipe"
   ],
   "metadata": {
    "id": "mvTrFuWUzEBp"
   },
   "id": "mvTrFuWUzEBp",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "id": "initial_id",
    "ExecuteTime": {
     "end_time": "2024-06-27T16:21:17.146315Z",
     "start_time": "2024-06-27T16:21:11.526767Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "import src.kfold.kfold_training_testing as kfold\n",
    "\n",
    "from src.types import *\n",
    "from src.models.main_model import OB_05Model\n",
    "from src.kfold.kfold_training_config import KFoldTrainingConfig\n",
    "\n",
    "output_dir = \"../output/kfold_model\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import logging\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((90, 90)),  # Resize images to 90x90\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "def get_trainset_colab(use_colored=False):\n",
    "    return datasets.ImageFolder(root=\"dataset/cleaned_images\", transform=transform)\n",
    "\n",
    "def split_into_n_sub_datasets_colab(folds: int):\n",
    "    _trainset = datasets.ImageFolder(root=r\"dataset/cleaned_images/\", transform=transform)\n",
    "    trainset_len = len(_trainset)\n",
    "\n",
    "    ratio = 1 / folds\n",
    "    fold_len = int(trainset_len * ratio)\n",
    "    last_fold_len = trainset_len - (folds - 1) * fold_len\n",
    "\n",
    "    lengths = ([fold_len] * (folds - 1)) + [last_fold_len]\n",
    "    return random_split(_trainset, lengths)\n",
    "\n",
    "def generate_hyper_parameters(_model: nn.Module):\n",
    "    initial_learning_rate = 0.0001\n",
    "    patience = 5\n",
    "    \n",
    "    _criterion = nn.CrossEntropyLoss()\n",
    "    _optimizer = optim.Adam(_model.parameters(), lr=initial_learning_rate, weight_decay=5e-2)\n",
    "    _scheduler = optim.lr_scheduler.ReduceLROnPlateau(_optimizer, 'min', factor=0.1, patience=patience)\n",
    "    return _criterion, _optimizer, _scheduler\n",
    "    \n",
    "    "
   ],
   "metadata": {
    "id": "ThTwn4HNzhoC",
    "ExecuteTime": {
     "end_time": "2024-06-27T16:23:20.911440Z",
     "start_time": "2024-06-27T16:23:20.903620Z"
    }
   },
   "id": "ThTwn4HNzhoC",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "id": "ac4a86b303ee7506",
    "ExecuteTime": {
     "end_time": "2024-06-27T16:23:21.314858Z",
     "start_time": "2024-06-27T16:23:21.247867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# logger for output (we can output training data to stdout or a file for example)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "trainset = get_trainset_colab()\n",
    "\n",
    "model = OB_05Model()\n",
    "criterion, optimizer, scheduler = generate_hyper_parameters(model)\n",
    "\n",
    "training_config = KFoldTrainingConfig(\n",
    "    output_dir=output_dir,\n",
    "    output_logger=logger,\n",
    "\n",
    "    dataset=trainset,\n",
    "    classes=trainset.classes,\n",
    "\n",
    "    num_folds=10,\n",
    "    epochs_per_fold=100,\n",
    "\n",
    "    model_type=OB_05Model,\n",
    "    generate_hyper_parameters=generate_hyper_parameters,\n",
    ")"
   ],
   "id": "ac4a86b303ee7506",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'dataset/cleaned_images'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mgetLogger()\n\u001B[0;32m      3\u001B[0m logger\u001B[38;5;241m.\u001B[39msetLevel(logging\u001B[38;5;241m.\u001B[39mINFO)\n\u001B[1;32m----> 5\u001B[0m trainset \u001B[38;5;241m=\u001B[39m \u001B[43mget_trainset_colab\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m model \u001B[38;5;241m=\u001B[39m OB_05Model()\n\u001B[0;32m      8\u001B[0m criterion, optimizer, scheduler \u001B[38;5;241m=\u001B[39m generate_hyper_parameters(model)\n",
      "Cell \u001B[1;32mIn[6], line 21\u001B[0m, in \u001B[0;36mget_trainset_colab\u001B[1;34m(use_colored)\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_trainset_colab\u001B[39m(use_colored\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m---> 21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdatasets\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mImageFolder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mroot\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdataset/cleaned_images\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Sandbox\\Python\\2\\Comp472Ai\\comp472\\Lib\\site-packages\\torchvision\\datasets\\folder.py:328\u001B[0m, in \u001B[0;36mImageFolder.__init__\u001B[1;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001B[0m\n\u001B[0;32m    319\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    320\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    321\u001B[0m     root: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    326\u001B[0m     allow_empty: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    327\u001B[0m ):\n\u001B[1;32m--> 328\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    329\u001B[0m \u001B[43m        \u001B[49m\u001B[43mroot\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    330\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    331\u001B[0m \u001B[43m        \u001B[49m\u001B[43mIMG_EXTENSIONS\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    332\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    333\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget_transform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_transform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    334\u001B[0m \u001B[43m        \u001B[49m\u001B[43mis_valid_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_valid_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    335\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_empty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_empty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    336\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    337\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimgs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msamples\n",
      "File \u001B[1;32m~\\Sandbox\\Python\\2\\Comp472Ai\\comp472\\Lib\\site-packages\\torchvision\\datasets\\folder.py:149\u001B[0m, in \u001B[0;36mDatasetFolder.__init__\u001B[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[0;32m    139\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    140\u001B[0m     root: Union[\u001B[38;5;28mstr\u001B[39m, Path],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    146\u001B[0m     allow_empty: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    147\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    148\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(root, transform\u001B[38;5;241m=\u001B[39mtransform, target_transform\u001B[38;5;241m=\u001B[39mtarget_transform)\n\u001B[1;32m--> 149\u001B[0m     classes, class_to_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind_classes\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroot\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    150\u001B[0m     samples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmake_dataset(\n\u001B[0;32m    151\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroot,\n\u001B[0;32m    152\u001B[0m         class_to_idx\u001B[38;5;241m=\u001B[39mclass_to_idx,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    155\u001B[0m         allow_empty\u001B[38;5;241m=\u001B[39mallow_empty,\n\u001B[0;32m    156\u001B[0m     )\n\u001B[0;32m    158\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader \u001B[38;5;241m=\u001B[39m loader\n",
      "File \u001B[1;32m~\\Sandbox\\Python\\2\\Comp472Ai\\comp472\\Lib\\site-packages\\torchvision\\datasets\\folder.py:234\u001B[0m, in \u001B[0;36mDatasetFolder.find_classes\u001B[1;34m(self, directory)\u001B[0m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfind_classes\u001B[39m(\u001B[38;5;28mself\u001B[39m, directory: Union[\u001B[38;5;28mstr\u001B[39m, Path]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[List[\u001B[38;5;28mstr\u001B[39m], Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mint\u001B[39m]]:\n\u001B[0;32m    208\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001B[39;00m\n\u001B[0;32m    209\u001B[0m \n\u001B[0;32m    210\u001B[0m \u001B[38;5;124;03m        directory/\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    232\u001B[0m \u001B[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001B[39;00m\n\u001B[0;32m    233\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 234\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfind_classes\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Sandbox\\Python\\2\\Comp472Ai\\comp472\\Lib\\site-packages\\torchvision\\datasets\\folder.py:41\u001B[0m, in \u001B[0;36mfind_classes\u001B[1;34m(directory)\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfind_classes\u001B[39m(directory: Union[\u001B[38;5;28mstr\u001B[39m, Path]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[List[\u001B[38;5;28mstr\u001B[39m], Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mint\u001B[39m]]:\n\u001B[0;32m     37\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001B[39;00m\n\u001B[0;32m     38\u001B[0m \n\u001B[0;32m     39\u001B[0m \u001B[38;5;124;03m    See :class:`DatasetFolder` for details.\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 41\u001B[0m     classes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(entry\u001B[38;5;241m.\u001B[39mname \u001B[38;5;28;01mfor\u001B[39;00m entry \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscandir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirectory\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m entry\u001B[38;5;241m.\u001B[39mis_dir())\n\u001B[0;32m     42\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m classes:\n\u001B[0;32m     43\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCouldn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt find any class folder in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdirectory\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] The system cannot find the path specified: 'dataset/cleaned_images'"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "id": "78def7bc68d0352f"
   },
   "cell_type": "markdown",
   "source": [
    "# K-fold"
   ],
   "id": "78def7bc68d0352f"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbba66574c3d5",
    "outputId": "1c13b441-171b-4820-e86c-3eb12861d7ee"
   },
   "cell_type": "code",
   "source": [
    "results_per_fold = kfold.kfold_cross_validation(training_config)"
   ],
   "id": "fbba66574c3d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "b3a60c6aa18fcb32",
    "outputId": "5c8de555-68ec-49cd-a2f1-b40a0fd04b63"
   },
   "cell_type": "code",
   "source": [
    "import src.types as tps\n",
    "\n",
    "# Directly evaluating the results\n",
    "evaluation_results_list = list(results_per_fold | pipe.select(lambda pair: pair[1]))\n",
    "df = tps.EvaluationResults.format_evaluation_results_as_df(evaluation_results_list)\n",
    "df.style"
   ],
   "id": "b3a60c6aa18fcb32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "4ed658b676845e43",
    "outputId": "133c0aaa-e323-4f6d-ae23-90eb7316512e"
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "import src.types as tps\n",
    "\n",
    "output_path = \"../output/kfold_model/results.pkl\"\n",
    "\n",
    "# Serialize the results into an output file\n",
    "with open(output_path, \"wb\") as file:\n",
    "    pickle.dump(results_per_fold, file)\n",
    "\n",
    "# Deserialize and load from a file\n",
    "with open(output_path, \"rb\") as f:\n",
    "    results_per_fold = pickle.load(f)\n",
    "\n",
    "evaluation_results_list = list(results_per_fold | pipe.select(lambda pair: pair[1]))\n",
    "df = tps.EvaluationResults.format_evaluation_results_as_df(evaluation_results_list)\n",
    "df.style"
   ],
   "id": "4ed658b676845e43",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
