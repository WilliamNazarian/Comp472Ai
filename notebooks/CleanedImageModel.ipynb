{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83fe88b-e0f5-4a00-86e1-e3a833e8b9dd",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.cuda as cuda\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, random_split"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e2ee5e-6dfb-4d16-ab21-55e20657eff7",
   "metadata": {},
   "source": [
    "num_epochs = 100\n",
    "num_classes = 4\n",
    "learning_rate = 0.001\n",
    "mean_gray = 0.1307\n",
    "stddev_gray = 0.3081\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((mean_gray,), (stddev_gray,))\n",
    "])\n",
    "\n",
    "# Load your custom dataset\n",
    "dataset_path = r\"C:\\Users\\yasse\\OneDrive\\Desktop\\cleaned_images\"\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33dd888a-ee0e-4e49-b43d-c4f5a78cad07",
   "metadata": {},
   "source": [
    "trainset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classes = trainset.classes\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "681055ad-40db-49a0-a5e7-c4618fbfff73",
   "metadata": {},
   "source": [
    "img = images[12].numpy()  # Get the 13th image in the batch (0-indexed)\n",
    "label = labels[12].item()  # Get the 13th label in the batch\n",
    "\n",
    "# Unnormalize the image for display\n",
    "\n",
    "\n",
    "# Check if the image is color or grayscale\n",
    "if img.shape[0] == 3:  # Color image\n",
    "    img = np.transpose(img, (1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
    "elif img.shape[0] == 1:  # Grayscale image\n",
    "    img = np.squeeze(img)  # Remove the channel dimension\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(img, cmap='gray' if img.ndim == 2 else None)\n",
    "plt.title(f'Label: {classes[label]}')\n",
    "plt.show()\n",
    "\n",
    "# Print the label\n",
    "print(f'Label: {classes[label]}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f6aa1a4-f94a-4cd8-ac07-67ef3de33828",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Calculate the number of samples for each subset\n",
    "num_train = int(0.7 * len(trainset))  # 70% for training\n",
    "num_val_test = len(trainset) - num_train  # Remaining 30% for validation and testing\n",
    "num_val = int(0.15 * len(trainset))  # 15% for validation\n",
    "num_test = num_val_test - num_val  # 15% for testing\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, temp_dataset = random_split(trainset, [num_train, num_val_test])\n",
    "val_dataset, test_dataset = random_split(temp_dataset, [num_val, num_test])\n",
    "\n",
    "# Create DataLoaders for each subset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Classes: {classes}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a506ca1b-5ac3-4455-8ced-c8909ab09d03",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d3ab767-c65c-4fd9-b469-44edbce9585d",
   "metadata": {},
   "source": [
    "class OB_05Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OB_05Model, self).__init__()\n",
    "\n",
    "        # Convolution Layer 1\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=5)  # 28 x 28 x 1 -> 24 x 24 x 20\n",
    "        self.relu1 = nn.ReLU()  # Activation function\n",
    "\n",
    "        # Convolution Layer 2\n",
    "        self.conv2 = nn.Conv2d(20, 30, kernel_size=5)  # 24 x 24 x 20 -> 20 x 20 x 30\n",
    "        self.conv2_drop = nn.Dropout2d(p=0.5)  # Dropout\n",
    "        self.maxpool2 = nn.MaxPool2d(2)  # Pooling layer 20 x 20 x 30 -> 10 x 10 x 30\n",
    "        self.relu2 = nn.ReLU()  # Activation function\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(3000, 500)  # 10 x 10 x 30 -> 3000 -> 500\n",
    "        self.fc2 = nn.Linear(500, 10)  # 500 -> 10\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolution Layer 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        # Convolution Layer 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv2_drop(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        # Flatten the tensor\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        # Fully connected layer 1\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        # Fully connected layer 2\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eecfe99a-b4a5-4144-87a5-5e9f2cce8f67",
   "metadata": {},
   "source": [
    "model = OB_05Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9) \n",
    "dummy_input = torch.randn(32, 1, 28, 28)  # Batch size of 32, 3 channels, 28x28 image\n",
    "output = model(dummy_input)\n",
    "print(output.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "372aaa23-5696-420c-aff7-69519c3d9ad5",
   "metadata": {},
   "source": [
    "train_loss = []\n",
    "valid_loss = []\n",
    "train_accuracy = []\n",
    "valid_accuracy = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    ############################\n",
    "    # Train\n",
    "    ############################\n",
    "    \n",
    "    iter_loss = 0.0\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "    \n",
    "    model.train()  # Put the network into training mode\n",
    "    \n",
    "    for i, (items, classes) in enumerate(train_loader):\n",
    "        \n",
    "        # Convert torch tensor to Variable\n",
    "        items = Variable(items)\n",
    "        classes = Variable(classes)\n",
    "        \n",
    "        # If we have GPU, shift the data to GPU\n",
    "        if torch.cuda.is_available():\n",
    "            items = items.cuda()\n",
    "            classes = classes.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()  # Clear off the gradients from any past operation\n",
    "        outputs = model(items)  # Do the forward pass\n",
    "        loss = criterion(outputs, classes)  # Calculate the loss\n",
    "        iter_loss += loss.item()  # Accumulate the loss\n",
    "        loss.backward()  # Calculate the gradients with help of back propagation\n",
    "        optimizer.step()  # Ask the optimizer to adjust the parameters based on the gradients\n",
    "        \n",
    "        # Record the correct predictions for training data \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == classes.data).sum().item()\n",
    "        iterations += 1\n",
    "    \n",
    "    # Record the training loss\n",
    "    train_loss.append(iter_loss / iterations)\n",
    "    # Record the training accuracy\n",
    "    train_accuracy.append((100 * correct / len(train_loader.dataset)))\n",
    "   \n",
    "\n",
    "    ############################\n",
    "    # Validate - How did we do on the unseen dataset?\n",
    "    ############################\n",
    "    \n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "\n",
    "    model.eval()  # Put the network into evaluate mode\n",
    "    \n",
    "    for i, (items, classes) in enumerate(val_loader):\n",
    "        \n",
    "        # Convert torch tensor to Variable\n",
    "        items = Variable(items)\n",
    "        classes = Variable(classes)\n",
    "        \n",
    "        # If we have GPU, shift the data to GPU\n",
    "        if torch.cuda.is_available():\n",
    "            items = items.cuda()\n",
    "            classes = classes.cuda()\n",
    "        \n",
    "        outputs = model(items)  # Do the forward pass\n",
    "        loss += criterion(outputs, classes).item()  # Calculate the loss\n",
    "        \n",
    "        # Record the correct predictions for validation data\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == classes.data).sum().item()\n",
    "        \n",
    "        iterations += 1\n",
    "\n",
    "    # Record the validation loss\n",
    "    valid_loss.append(loss / iterations)\n",
    "    # Record the validation accuracy\n",
    "    valid_accuracy.append(correct / len(val_loader.dataset) * 100.0)\n",
    "\n",
    "    print('Epoch %d/%d, Tr Loss: %.4f, Tr Acc: %.4f, Val Loss: %.4f, Val Acc: %.4f'\n",
    "          % (epoch + 1, num_epochs, train_loss[-1], train_accuracy[-1], \n",
    "             valid_loss[-1], valid_accuracy[-1]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147b1acb-1d31-4b75-8e99-6a718881a72d",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "928b5b4b-d020-4156-91e2-0da6d9526e0c",
   "metadata": {},
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables to track correct predictions and total samples\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Disable gradient computation for evaluation\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        # Get predictions from the maximum value\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # Update total number of labels\n",
    "        total += labels.size(0)\n",
    "        # Update the number of correct predictions\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = (correct / total) * 100\n",
    "print('Test Accuracy of the model on  test images: {:.2f} %'.format(accuracy))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfb0fbf6-1fe7-451b-a10e-714955e64a9d",
   "metadata": {},
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables to track correct predictions and total samples\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Disable gradient computation for evaluation\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        # Get predictions from the maximum value\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # Update total number of labels\n",
    "        total += labels.size(0)\n",
    "        # Update the number of correct predictions\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = (correct / total) * 100\n",
    "print('Validation Accuracy of the model: {:.2f} %'.format(accuracy))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cef357d6-3b63-4995-adf0-a6b76f6a5bb1",
   "metadata": {},
   "source": [
    "Save the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7518c471-6a59-4a8e-823c-fc4c2ec58cb7",
   "metadata": {},
   "source": [
    "# Define the path and file name to save the model\n",
    "model_path = r\"C:\\Users\\yasse\\OneDrive\\Desktop\\ModelPath\\model1.pth\"\n",
    "\n",
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92f15d2-2c0f-463c-92a6-2203d3f315db",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
